---
---

@techreport{krentzel_clem-reg_2023,
	type = {preprint},
	title = {{CLEM}-{Reg}: {An} automated point cloud based registration algorithm for correlative light and volume electron microscopy},
	shorttitle = {{CLEM}-{Reg}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2023.05.11.540445},
	abstract = {Correlative light and volume electron microscopy (vCLEM) is a powerful imaging technique that enables visualisation of fluorescently labelled proteins within their ultrastructural context on a subcellular level. Currently, expert microscopists find the alignment between acquisitions by manually placing landmarks on structures that can be recognised in both imaging modalities. The manual nature of the process severely impacts throughput and may introduce bias. This paper presents CLEM-Reg, a workflow that automates the alignment of vCLEM datasets by leveraging point cloud based registration techniques. Point clouds are obtained by segmenting internal landmarks, such as mitochondria, through a pattern recognition approach that includes machine-learning. CLEM-Reg is a fully automated and reproducible vCLEM alignment workflow that requires no prior expert knowledge. When benchmarked against experts on two newly acquired vCLEM datasets, CLEM-Reg achieves near expert-level registration performance. The datasets are made available in the EMPIAR public image archive for reuse in testing and developing multimodal registration algorithms by the wider community. A napari plugin integrating the algorithm is also provided to aid adoption by end-users. The source-code for CLEM-Reg and installation instructions can be found at
            https://github.com/krentzd/napari-clemreg
            .},
	language = {en},
	urldate = {2024-02-05},
	institution = {Cell Biology},
	author = {Krentzel, Daniel and Elphick, Matouš and Domart, Marie-Charlotte and Peddie, Christopher J. and Laine, Romain F. and Henriques, Ricardo and Collinson, Lucy M. and Jones, Martin L.},
	month = may,
	year = {2023},
	doi = {10.1101/2023.05.11.540445},
    pdf={https://www.biorxiv.org/content/10.1101/2023.05.11.540445v2.full.pdf},
    journal={bioRxiv},
    abbr={bioRxiv},
    code={https://github.com/krentzd/napari-clemreg},
    selected={true},
    preview={clemreg.gif}
}

@misc{bernárdez2024icmltopologicaldeeplearning,
      title={ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain},
      author={Guillermo Bernárdez and Lev Telyatnikov and Marco Montagna and Federica Baccini and Mathilde Papillon and Miquel Ferriol-Galmés and Mustafa Hajij and Theodore Papamarkou and Maria Sofia Bucarelli and Olga Zaghen and Johan Mathe and Audun Myers and Scott Mahan and Hansen Lillemark and Sharvaree Vadgama and Erik Bekkers and Tim Doster and Tegan Emerson and Henry Kvinge and Katrina Agate and Nesreen K Ahmed and Pengfei Bai and Michael Banf and Claudio Battiloro and Maxim Beketov and Paul Bogdan and Martin Carrasco and Andrea Cavallo and Yun Young Choi and George Dasoulas and Matouš Elphick and Giordan Escalona and Dominik Filipiak and Halley Fritze and Thomas Gebhart and Manel Gil-Sorribes and Salvish Goomanee and Victor Guallar and Liliya Imasheva and Andrei Irimia and Hongwei Jin and Graham Johnson and Nikos Kanakaris and Boshko Koloski and Veljko Kovač and Manuel Lecha and Minho Lee and Pierrick Leroy and Theodore Long and German Magai and Alvaro Martinez and Marissa Masden and Sebastian Mežnar and Bertran Miquel-Oliver and Alexis Molina and Alexander Nikitin and Marco Nurisso and Matt Piekenbrock and Yu Qin and Patryk Rygiel and Alessandro Salatiello and Max Schattauer and Pavel Snopov and Julian Suk and Valentina Sánchez and Mauricio Tec and Francesco Vaccarino and Jonas Verhellen and Frederic Wantiez and Alexander Weers and Patrik Zajec and Blaž Škrlj and Nina Miolane},
      year={2024},
      abstract={This paper describes the 2nd edition of the ICML Topological Deep Learning Challenge that was hosted within the ICML 2024 ELLIS Workshop on Geometry-grounded Representation Learning and Generative Modeling (GRaM). The challenge focused on the problem of representing data in different discrete topological domains in order to bridge the gap between Topological Deep Learning (TDL) and other types of structured datasets (e.g. point clouds, graphs). Specifically, participants were asked to design and implement topological liftings, i.e. mappings between different data structures and topological domains --like hypergraphs, or simplicial/cell/combinatorial complexes. The challenge received 52 submissions satisfying all the requirements. This paper introduces the main scope of the challenge, and summarizes the main results and findings.},
      eprint={2409.05211},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.05211},
      preview={domain_categories_with_relations.png},
      pdf={https://arxiv.org/pdf/2409.05211},
      doi={10.48550/arXiv.2409.05211},
      code={https://github.com/pyt-team/challenge-icml-2024}
}

@misc{elphick2024latentrepresentationsfoundationmodels,
      title={Are the Latent Representations of Foundation Models for Pathology Invariant to Rotation?},
      author={Matouš Elphick and Samra Turajlic and Guang Yang},
      year={2024},
      eprint={2412.11938},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2412.11938},
      preview={distance-plot.png},
      pdf={https://arxiv.org/pdf/2412.11938},
      code={https://github.com/MatousE/rot-invariance-analysis}

}